{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b8u6d2lgWGOo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8u6d2lgWGOo",
        "outputId": "355961a3-dea2-42a3-a3c0-c78d0e8d8c66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (3.0.2)\n",
            "Collecting torch\n",
            "  Downloading torch-2.5.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: filelock in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (2.1.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (0.26.1)\n",
            "Requirement already satisfied: packaging in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from torch) (4.12.2)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Downloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: setuptools in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from torch) (75.1.0)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
            "  Downloading tokenizers-0.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from pandas->datasets) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading torch-2.5.0-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[38;2;249;38;114m━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/906.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:05:35\u001b[0m^C\n",
            "\u001b[2K   \u001b[38;2;249;38;114m━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.0/906.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:05:36\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install datasets torch transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "U7qWY5MXJj23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qWY5MXJj23",
        "outputId": "cd01585e-a09c-4ceb-858d-48d1f1b602fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (2.1.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (0.26.1)\n",
            "Requirement already satisfied: packaging in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from pandas->datasets) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/ghannam/anaconda3/envs/mlflow/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "30873529",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:13.153229Z",
          "iopub.status.busy": "2024-10-16T18:24:13.152633Z",
          "iopub.status.idle": "2024-10-16T18:24:31.110917Z",
          "shell.execute_reply": "2024-10-16T18:24:31.109537Z"
        },
        "id": "30873529",
        "papermill": {
          "duration": 17.975012,
          "end_time": "2024-10-16T18:24:31.113684",
          "exception": false,
          "start_time": "2024-10-16T18:24:13.138672",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-24 16:32:56.878394: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-24 16:32:56.887096: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-24 16:32:56.905558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-24 16:32:56.936775: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-24 16:32:56.943842: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-24 16:32:56.967049: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-24 16:32:58.861484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Flatten, LSTM , GRU\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = (8, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P6zrRbk2WpjJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "P6zrRbk2WpjJ",
        "outputId": "6b53750c-28bf-4cc3-b649-14064458e986"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f20da5e6-ec66-4822-b8f8-94bcc9842812\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f20da5e6-ec66-4822-b8f8-94bcc9842812\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "# Upload the kaggle.json to Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iPJ9LtbnXAiW",
      "metadata": {
        "id": "iPJ9LtbnXAiW"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SY3nLk4ZXlvB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY3nLk4ZXlvB",
        "outputId": "9a7de8ea-b4f1-4ed5-92cd-436331975f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/scodepy/customer-support-intent-dataset\n",
            "License(s): unknown\n",
            "customer-support-intent-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d scodepy/customer-support-intent-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oCsOjxV9cE1k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCsOjxV9cE1k",
        "outputId": "909cd081-f0a6-494b-ac60-718745ca8c25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  customer-support-intent-dataset.zip\n",
            "replace ./data/Bitext_Sample_Customer_Service_Testing_Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip customer-support-intent-dataset.zip -d ./data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wYcjQ-EUcTcu",
      "metadata": {
        "id": "wYcjQ-EUcTcu"
      },
      "outputs": [],
      "source": [
        "!ls data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "PATRVi8Bcc0i",
      "metadata": {
        "id": "PATRVi8Bcc0i"
      },
      "outputs": [],
      "source": [
        "df_train=pd.read_csv(\"data/Bitext_Sample_Customer_Service_Training_Dataset.csv\")\n",
        "df_test=pd.read_csv(\"data/Bitext_Sample_Customer_Service_Testing_Dataset.csv\")\n",
        "df_val=pd.read_csv(\"data/Bitext_Sample_Customer_Service_Validation_Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fab4576",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:31.140966Z",
          "iopub.status.busy": "2024-10-16T18:24:31.140193Z",
          "iopub.status.idle": "2024-10-16T18:24:31.200098Z",
          "shell.execute_reply": "2024-10-16T18:24:31.199019Z"
        },
        "id": "9fab4576",
        "papermill": {
          "duration": 0.07643,
          "end_time": "2024-10-16T18:24:31.202801",
          "exception": false,
          "start_time": "2024-10-16T18:24:31.126371",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# train_path=\"/kaggle/input/customer-support-intent-dataset/Bitext_Sample_Customer_Service_Training_Dataset.csv\"\n",
        "# valid_path=\"/kaggle/input/customer-support-intent-dataset/Bitext_Sample_Customer_Service_Validation_Dataset.csv\"\n",
        "# test_data=\"/kaggle/input/customer-support-intent-dataset/Bitext_Sample_Customer_Service_Testing_Dataset.csv\"\n",
        "# df_train=pd.read_csv(train_path)\n",
        "# df_val=pd.read_csv(valid_path)\n",
        "# df_test=pd.read_csv(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hAE432QhlQmM",
      "metadata": {
        "id": "hAE432QhlQmM"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KPwFSKcefrUN",
      "metadata": {
        "id": "KPwFSKcefrUN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4df11ef1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:31.230869Z",
          "iopub.status.busy": "2024-10-16T18:24:31.230392Z",
          "iopub.status.idle": "2024-10-16T18:24:31.253106Z",
          "shell.execute_reply": "2024-10-16T18:24:31.251898Z"
        },
        "id": "4df11ef1",
        "outputId": "c2438613-9fbc-48f3-f33a-e5cc8bb634bb",
        "papermill": {
          "duration": 0.039045,
          "end_time": "2024-10-16T18:24:31.255654",
          "exception": false,
          "start_time": "2024-10-16T18:24:31.216609",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>intent</th>\n",
              "      <th>category</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>would it be possible to cancel the order I made?</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>BIP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cancelling order</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>BK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I need assistance canceling the last order I h...</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>problem with canceling the order I made</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I don't know how to cancel the order I made</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           utterance        intent category  \\\n",
              "0   would it be possible to cancel the order I made?  cancel_order    ORDER   \n",
              "1                                   cancelling order  cancel_order    ORDER   \n",
              "2  I need assistance canceling the last order I h...  cancel_order    ORDER   \n",
              "3            problem with canceling the order I made  cancel_order    ORDER   \n",
              "4        I don't know how to cancel the order I made  cancel_order    ORDER   \n",
              "\n",
              "  tags  \n",
              "0  BIP  \n",
              "1   BK  \n",
              "2    B  \n",
              "3    B  \n",
              "4    B  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7e488087",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:31.283411Z",
          "iopub.status.busy": "2024-10-16T18:24:31.282519Z",
          "iopub.status.idle": "2024-10-16T18:24:31.289846Z",
          "shell.execute_reply": "2024-10-16T18:24:31.288634Z"
        },
        "id": "7e488087",
        "outputId": "ed5d2bbc-893d-41db-925c-334b11b643ec",
        "papermill": {
          "duration": 0.023815,
          "end_time": "2024-10-16T18:24:31.292205",
          "exception": false,
          "start_time": "2024-10-16T18:24:31.268390",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6539, 4)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "eddf9665",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:31.319926Z",
          "iopub.status.busy": "2024-10-16T18:24:31.319464Z",
          "iopub.status.idle": "2024-10-16T18:24:31.326748Z",
          "shell.execute_reply": "2024-10-16T18:24:31.325646Z"
        },
        "id": "eddf9665",
        "outputId": "6060d071-be19-45db-da67-c21297678393",
        "papermill": {
          "duration": 0.024174,
          "end_time": "2024-10-16T18:24:31.329229",
          "exception": false,
          "start_time": "2024-10-16T18:24:31.305055",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(818, 4)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "Ssn_QoYzleR7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssn_QoYzleR7",
        "outputId": "0d7d2674-6aed-4935-f0f5-740b42185182"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(818, 4)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "-gcnEv7ylmwM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gcnEv7ylmwM",
        "outputId": "ff5bacbf-b8c8-438d-9f17-5a02e41141bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6539 entries, 0 to 6538\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   utterance  6539 non-null   object\n",
            " 1   intent     6539 non-null   object\n",
            " 2   category   6539 non-null   object\n",
            " 3   tags       6539 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 204.5+ KB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Pdo_F_CylxRX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "Pdo_F_CylxRX",
        "outputId": "2d3642ed-95a7-45e5-fbcf-57bd03d40cf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "intent\n",
              "get_invoice                 268\n",
              "payment_issue               263\n",
              "check_invoice               258\n",
              "contact_customer_service    253\n",
              "complaint                   252\n",
              "review                      248\n",
              "cancel_order                246\n",
              "check_cancellation_fee      246\n",
              "check_payment_methods       246\n",
              "set_up_shipping_address     246\n",
              "track_order                 245\n",
              "place_order                 243\n",
              "check_refund_policy         240\n",
              "get_refund                  239\n",
              "registration_problems       239\n",
              "recover_password            239\n",
              "track_refund                239\n",
              "newsletter_subscription     238\n",
              "create_account              237\n",
              "delivery_options            236\n",
              "delete_account              236\n",
              "delivery_period             236\n",
              "edit_account                233\n",
              "change_order                232\n",
              "switch_account              228\n",
              "change_shipping_address     228\n",
              "contact_human_agent         225\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['intent'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "gGIIQajNoAdg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "gGIIQajNoAdg",
        "outputId": "b49124ce-b889-4414-af03-f614ba52364a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "category\n",
              "ACCOUNT             1412\n",
              "ORDER                966\n",
              "REFUND               718\n",
              "INVOICE              526\n",
              "PAYMENT              509\n",
              "FEEDBACK             500\n",
              "CONTACT              478\n",
              "SHIPPING_ADDRESS     474\n",
              "DELIVERY             472\n",
              "CANCELLATION_FEE     246\n",
              "NEWSLETTER           238\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train[\"category\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6xKLHb73pjcZ",
      "metadata": {
        "id": "6xKLHb73pjcZ"
      },
      "source": [
        "# data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "26c92d80",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:31.357351Z",
          "iopub.status.busy": "2024-10-16T18:24:31.356551Z",
          "iopub.status.idle": "2024-10-16T18:24:31.362801Z",
          "shell.execute_reply": "2024-10-16T18:24:31.361515Z"
        },
        "id": "26c92d80",
        "papermill": {
          "duration": 0.023058,
          "end_time": "2024-10-16T18:24:31.365224",
          "exception": false,
          "start_time": "2024-10-16T18:24:31.342166",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase text\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6772a7e4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:31.393745Z",
          "iopub.status.busy": "2024-10-16T18:24:31.393268Z",
          "iopub.status.idle": "2024-10-16T18:24:31.463151Z",
          "shell.execute_reply": "2024-10-16T18:24:31.462132Z"
        },
        "id": "6772a7e4",
        "papermill": {
          "duration": 0.087381,
          "end_time": "2024-10-16T18:24:31.465874",
          "exception": false,
          "start_time": "2024-10-16T18:24:31.378493",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_train['utterance']=df_train['utterance'].apply(preprocess_text)\n",
        "df_test['utterance']=df_test['utterance'].apply(preprocess_text)\n",
        "df_val['utterance']=df_val['utterance'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f0276a2b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:31.494615Z",
          "iopub.status.busy": "2024-10-16T18:24:31.494175Z",
          "iopub.status.idle": "2024-10-16T18:24:31.500240Z",
          "shell.execute_reply": "2024-10-16T18:24:31.499116Z"
        },
        "id": "f0276a2b",
        "papermill": {
          "duration": 0.023557,
          "end_time": "2024-10-16T18:24:31.502886",
          "exception": false,
          "start_time": "2024-10-16T18:24:31.479329",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_texts = df_train['utterance'].tolist()\n",
        "train_labels = df_train['intent'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f6222b48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:31.532587Z",
          "iopub.status.busy": "2024-10-16T18:24:31.532178Z",
          "iopub.status.idle": "2024-10-16T18:24:31.541138Z",
          "shell.execute_reply": "2024-10-16T18:24:31.540028Z"
        },
        "id": "f6222b48",
        "outputId": "5a096ef8-86d4-4e1a-e1da-27d70c4ff365",
        "papermill": {
          "duration": 0.027278,
          "end_time": "2024-10-16T18:24:31.543605",
          "exception": false,
          "start_time": "2024-10-16T18:24:31.516327",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6539, 6539)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_texts), len(train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BZ5mwmkNiouS",
      "metadata": {
        "id": "BZ5mwmkNiouS"
      },
      "source": [
        "# MODELING"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Lyb-2gKKiyaH",
      "metadata": {
        "id": "Lyb-2gKKiyaH"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "502cb372",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:31.571845Z",
          "iopub.status.busy": "2024-10-16T18:24:31.571401Z",
          "iopub.status.idle": "2024-10-16T18:24:33.108305Z",
          "shell.execute_reply": "2024-10-16T18:24:33.106907Z"
        },
        "id": "502cb372",
        "outputId": "ca99b74b-b332-49be-c971-aeb19429114e",
        "papermill": {
          "duration": 1.55401,
          "end_time": "2024-10-16T18:24:33.110888",
          "exception": false,
          "start_time": "2024-10-16T18:24:31.556878",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/ghannam/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/home/ghannam/nltk_data'\n    - '/home/ghannam/anaconda3/envs/mlflow/nltk_data'\n    - '/home/ghannam/anaconda3/envs/mlflow/share/nltk_data'\n    - '/home/ghannam/anaconda3/envs/mlflow/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Tokenize the text (you can use NLTK's word_tokenize or simply split)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train_texts \u001b[38;5;241m=\u001b[39m [\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m train_texts]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert the tokenized texts to strings (as needed for vectorization)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m train_texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m train_texts]\n",
            "File \u001b[0;32m~/anaconda3/envs/mlflow/lib/python3.12/site-packages/nltk/tokenize/__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    145\u001b[0m     ]\n",
            "File \u001b[0;32m~/anaconda3/envs/mlflow/lib/python3.12/site-packages/nltk/tokenize/__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
            "File \u001b[0;32m~/anaconda3/envs/mlflow/lib/python3.12/site-packages/nltk/tokenize/__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/mlflow/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/mlflow/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
            "File \u001b[0;32m~/anaconda3/envs/mlflow/lib/python3.12/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/home/ghannam/nltk_data'\n    - '/home/ghannam/anaconda3/envs/mlflow/nltk_data'\n    - '/home/ghannam/anaconda3/envs/mlflow/share/nltk_data'\n    - '/home/ghannam/anaconda3/envs/mlflow/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ensure you have downloaded necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize the text (you can use NLTK's word_tokenize or simply split)\n",
        "train_texts = [nltk.word_tokenize(text) for text in train_texts]\n",
        "\n",
        "# Convert the tokenized texts to strings (as needed for vectorization)\n",
        "train_texts = [\" \".join(text) for text in train_texts]\n",
        "\n",
        "# Vectorize the text using scikit-learn's CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(train_texts)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = f1_score(y_test, y_pred, average = 'macro')\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2b11461d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:33.139578Z",
          "iopub.status.busy": "2024-10-16T18:24:33.138827Z",
          "iopub.status.idle": "2024-10-16T18:24:33.147801Z",
          "shell.execute_reply": "2024-10-16T18:24:33.146583Z"
        },
        "id": "2b11461d",
        "outputId": "ee434c6c-07ea-4ddf-f92b-5bc4b5f0de91",
        "papermill": {
          "duration": 0.02638,
          "end_time": "2024-10-16T18:24:33.150659",
          "exception": false,
          "start_time": "2024-10-16T18:24:33.124279",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: I need help with my order --> Predicted Intent: cancel_order\n",
            "Text: Thank you for your help --> Predicted Intent: review\n"
          ]
        }
      ],
      "source": [
        "# Example test sentences to classify\n",
        "new_texts = [\"I need help with my order\", \"Thank you for your help\"]\n",
        "\n",
        "# Tokenize the new texts\n",
        "new_texts_tokenized = [\" \".join(nltk.word_tokenize(text)) for text in new_texts]\n",
        "\n",
        "# Vectorize the new texts (using the same vectorizer that was fitted on the training data)\n",
        "new_texts_vectorized = vectorizer.transform(new_texts_tokenized)\n",
        "\n",
        "# Make predictions using the trained classifier\n",
        "predictions = classifier.predict(new_texts_vectorized)\n",
        "\n",
        "# Output the predictions\n",
        "for text, label in zip(new_texts, predictions):\n",
        "    print(f\"Text: {text} --> Predicted Intent: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbee6f00",
      "metadata": {
        "id": "cbee6f00",
        "papermill": {
          "duration": 0.012896,
          "end_time": "2024-10-16T18:24:33.177114",
          "exception": false,
          "start_time": "2024-10-16T18:24:33.164218",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "65c91d6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:33.206020Z",
          "iopub.status.busy": "2024-10-16T18:24:33.205036Z",
          "iopub.status.idle": "2024-10-16T18:24:33.213539Z",
          "shell.execute_reply": "2024-10-16T18:24:33.212372Z"
        },
        "id": "65c91d6a",
        "outputId": "1235f090-2269-4b73-fc32-a6572fa54885",
        "papermill": {
          "duration": 0.02668,
          "end_time": "2024-10-16T18:24:33.217124",
          "exception": false,
          "start_time": "2024-10-16T18:24:33.190444",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 6539,\n  \"fields\": [\n    {\n      \"column\": \"utterance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6529,\n        \"samples\": [\n          \"i want assistance solving issues with payment\",\n          \"help to create another online account\",\n          \"i want help adding several items to an order\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"contact_customer_service\",\n          \"delivery_period\",\n          \"contact_human_agent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"REFUND\",\n          \"ORDER\",\n          \"DELIVERY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 107,\n        \"samples\": [\n          \"BZ\",\n          \"BEP\",\n          \"BMP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-68e73614-bac8-4b88-88c0-c54a49eee181\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>intent</th>\n",
              "      <th>category</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>would it be possible to cancel the order i made</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>BIP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cancelling order</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>BK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i need assistance canceling the last order i h...</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>problem with canceling the order i made</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i dont know how to cancel the order i made</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68e73614-bac8-4b88-88c0-c54a49eee181')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68e73614-bac8-4b88-88c0-c54a49eee181 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68e73614-bac8-4b88-88c0-c54a49eee181');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15111a18-86c0-4dbe-a6ad-efdb7768ae2f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15111a18-86c0-4dbe-a6ad-efdb7768ae2f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15111a18-86c0-4dbe-a6ad-efdb7768ae2f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                           utterance        intent category  \\\n",
              "0    would it be possible to cancel the order i made  cancel_order    ORDER   \n",
              "1                                   cancelling order  cancel_order    ORDER   \n",
              "2  i need assistance canceling the last order i h...  cancel_order    ORDER   \n",
              "3            problem with canceling the order i made  cancel_order    ORDER   \n",
              "4         i dont know how to cancel the order i made  cancel_order    ORDER   \n",
              "\n",
              "  tags  \n",
              "0  BIP  \n",
              "1   BK  \n",
              "2    B  \n",
              "3    B  \n",
              "4    B  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "58ee93bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:33.245971Z",
          "iopub.status.busy": "2024-10-16T18:24:33.245517Z",
          "iopub.status.idle": "2024-10-16T18:24:33.253128Z",
          "shell.execute_reply": "2024-10-16T18:24:33.252049Z"
        },
        "id": "58ee93bd",
        "outputId": "af416812-fd8d-4bf4-c2bf-c3cd239140d2",
        "papermill": {
          "duration": 0.024629,
          "end_time": "2024-10-16T18:24:33.255398",
          "exception": false,
          "start_time": "2024-10-16T18:24:33.230769",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['utterance', 'intent', 'category', 'tags'], dtype='object')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9dbf680b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:33.284267Z",
          "iopub.status.busy": "2024-10-16T18:24:33.283819Z",
          "iopub.status.idle": "2024-10-16T18:24:33.290758Z",
          "shell.execute_reply": "2024-10-16T18:24:33.289542Z"
        },
        "id": "9dbf680b",
        "papermill": {
          "duration": 0.023909,
          "end_time": "2024-10-16T18:24:33.293024",
          "exception": false,
          "start_time": "2024-10-16T18:24:33.269115",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_texts = df_test['utterance'].values\n",
        "test_labels = df_test['intent'].values\n",
        "X_val = df_val[\"utterance\"].to_list()\n",
        "y_val = df_val[\"intent\"].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "52aE7ecwb_9X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52aE7ecwb_9X",
        "outputId": "fc1606f4-8629-440a-a934-dd63f5337b4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "818"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7246300c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:33.322342Z",
          "iopub.status.busy": "2024-10-16T18:24:33.321903Z",
          "iopub.status.idle": "2024-10-16T18:24:33.330152Z",
          "shell.execute_reply": "2024-10-16T18:24:33.328890Z"
        },
        "id": "7246300c",
        "papermill": {
          "duration": 0.026113,
          "end_time": "2024-10-16T18:24:33.332808",
          "exception": false,
          "start_time": "2024-10-16T18:24:33.306695",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_labels)\n",
        "y_test = label_encoder.transform(test_labels)\n",
        "y_val = label_encoder.transform(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "rIMRyH_QRfB_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIMRyH_QRfB_",
        "outputId": "11b14a8b-437b-44b0-e418-216263327f70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6539, 6539)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_texts), len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "89e66f47",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:33.362451Z",
          "iopub.status.busy": "2024-10-16T18:24:33.361473Z",
          "iopub.status.idle": "2024-10-16T18:24:33.603034Z",
          "shell.execute_reply": "2024-10-16T18:24:33.601832Z"
        },
        "id": "89e66f47",
        "papermill": {
          "duration": 0.259584,
          "end_time": "2024-10-16T18:24:33.606053",
          "exception": false,
          "start_time": "2024-10-16T18:24:33.346469",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=5000)  # Keep the top 5000 words\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "val_sequences = tokenizer.texts_to_sequences(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "357999c4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:33.636147Z",
          "iopub.status.busy": "2024-10-16T18:24:33.635684Z",
          "iopub.status.idle": "2024-10-16T18:24:33.680020Z",
          "shell.execute_reply": "2024-10-16T18:24:33.678839Z"
        },
        "id": "357999c4",
        "papermill": {
          "duration": 0.06282,
          "end_time": "2024-10-16T18:24:33.682826",
          "exception": false,
          "start_time": "2024-10-16T18:24:33.620006",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "max_sequence_length = max([len(seq) for seq in train_sequences])\n",
        "X_train = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
        "x_val = pad_sequences(val_sequences, maxlen=max_sequence_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "YUB2nLC4dgJD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUB2nLC4dgJD",
        "outputId": "f2d3aba7-5333-4962-d7a1-5e9cea5446b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "818"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kvWR6iPkCBd6",
      "metadata": {
        "id": "kvWR6iPkCBd6"
      },
      "outputs": [],
      "source": [
        "# def preprocessing(data):\n",
        "#     tokenizer = Tokenizer(num_words=5000)\n",
        "#     tokenizer.fit_on_texts(data)\n",
        "#     sequences = tokenizer.texts_to_sequences(data)\n",
        "#     max_sequence_length = max([len(seq) for seq in sequences])\n",
        "#     data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "#     return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SGDlvHedIxYo",
      "metadata": {
        "id": "SGDlvHedIxYo"
      },
      "outputs": [],
      "source": [
        "# tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "# def preprocessing_gpt(data):\n",
        "#     global max_sequence_length\n",
        "\n",
        "#     # Calculate max_sequence_length only once\n",
        "#     if max_sequence_length is None:\n",
        "#         tokenizer.fit_on_texts(data)\n",
        "#         sequences = tokenizer.texts_to_sequences(data)\n",
        "#         max_sequence_length = max(len(seq) for seq in sequences)\n",
        "\n",
        "#     # Reuse the same tokenizer and pad with the fixed max length\n",
        "#     tokenizer = Tokenizer(num_words=5000)\n",
        "#     tokenizer.fit_on_texts(data)\n",
        "#     sequences = tokenizer.texts_to_sequences(data)\n",
        "#     data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "#     return data, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VeMifMOEJKde",
      "metadata": {
        "id": "VeMifMOEJKde"
      },
      "outputs": [],
      "source": [
        "# x_train, x_test, x_val = preprocessing1(train_texts,test_texts,X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sqs5kLKyV3dB",
      "metadata": {
        "id": "Sqs5kLKyV3dB"
      },
      "outputs": [],
      "source": [
        "# x_train = preprocessing_gpt(train_texts)\n",
        "# x_test = preprocessing_gpt(test_texts)\n",
        "# x_val = preprocessing_gpt(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YAbcf0QhG6aL",
      "metadata": {
        "id": "YAbcf0QhG6aL"
      },
      "outputs": [],
      "source": [
        "# x_train = preprocessing(train_texts)\n",
        "# x_test = preprocessing(test_texts)\n",
        "# x_val = preprocessing(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "gEPdUSN9UCUi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEPdUSN9UCUi",
        "outputId": "24b239d3-6c48-482f-fed5-1c01a1c0b043"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6539"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "780ea96e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T18:24:33.712416Z",
          "iopub.status.busy": "2024-10-16T18:24:33.711960Z",
          "iopub.status.idle": "2024-10-16T18:24:34.553288Z",
          "shell.execute_reply": "2024-10-16T18:24:34.551797Z"
        },
        "id": "780ea96e",
        "outputId": "c9e7b369-a6bd-4966-98d2-c54843f478d2",
        "papermill": {
          "duration": 0.858387,
          "end_time": "2024-10-16T18:24:34.555275",
          "exception": true,
          "start_time": "2024-10-16T18:24:33.696888",
          "status": "failed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=50, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(128))\n",
        "model.add(Dense(27, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d519137a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d519137a",
        "outputId": "20002e8c-6601-4106-dfdf-ac1ec2a667ad",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.4061 - loss: 2.7250 - val_accuracy: 0.8435 - val_loss: 0.8520\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9278 - loss: 0.5183 - val_accuracy: 0.9609 - val_loss: 0.2474\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9785 - loss: 0.1517 - val_accuracy: 0.9731 - val_loss: 0.1382\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.0662 - val_accuracy: 0.9804 - val_loss: 0.1063\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9961 - loss: 0.0442 - val_accuracy: 0.9841 - val_loss: 0.0776\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9987 - loss: 0.0227 - val_accuracy: 0.9878 - val_loss: 0.0662\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9994 - loss: 0.0149 - val_accuracy: 0.9890 - val_loss: 0.0510\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0105 - val_accuracy: 0.9866 - val_loss: 0.0468\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0077 - val_accuracy: 0.9890 - val_loss: 0.0461\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0057 - val_accuracy: 0.9890 - val_loss: 0.0442\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f039c4387c0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "Ro_xmyv3YBTQ",
      "metadata": {
        "id": "Ro_xmyv3YBTQ"
      },
      "outputs": [],
      "source": [
        "import pickle as pk\n",
        "#save tokinizer\n",
        "pk.dump(tokenizer,open(\"tokenizer.pkl\",\"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "TFFhkRkhYNGJ",
      "metadata": {
        "id": "TFFhkRkhYNGJ"
      },
      "outputs": [],
      "source": [
        "#save encoder\n",
        "pk.dump(label_encoder,open(\"label_encoder.pkl\",\"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "jLln-XRNYU9H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLln-XRNYU9H",
        "outputId": "5f429ddc-bfe3-43f6-dbad-8f3d285694bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "model.save('model.h5') # save model\n",
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('model.h5') # load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87fbd5a0",
      "metadata": {
        "id": "87fbd5a0",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model.save(\"rnn_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U2Rx4I2P_Z7N",
      "metadata": {
        "id": "U2Rx4I2P_Z7N"
      },
      "outputs": [],
      "source": [
        "model  = load_model(\"rnn_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vgr5y7K1_jKX",
      "metadata": {
        "id": "vgr5y7K1_jKX"
      },
      "outputs": [],
      "source": [
        "with open('/content/intent_responses.json', 'r') as f:\n",
        "    responses = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yz4jkRuPAmq3",
      "metadata": {
        "id": "yz4jkRuPAmq3"
      },
      "outputs": [],
      "source": [
        "def preprocess_input(input_text):\n",
        "    input_text = input_text.lower()\n",
        "    input_text = re.sub(r'\\s+', ' ', input_text)  # Remove extra spaces\n",
        "    input_text = re.sub(r'[^\\w\\s]', '', input_text)  # Remove punctuation\n",
        "\n",
        "    # Tokenize and pad the input text\n",
        "    input_sequence = tokenizer.texts_to_sequences([input_text])  # Pass as a list\n",
        "    input_sequence = pad_sequences(input_sequence, maxlen=20)  # Use a fixed max length\n",
        "\n",
        "    return input_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "huo1lEXcCKn4",
      "metadata": {
        "id": "huo1lEXcCKn4"
      },
      "outputs": [],
      "source": [
        "def get_response(user_input):\n",
        "    # Step 5: Preprocess the user input\n",
        "    input_vector = preprocess_input(user_input)\n",
        "\n",
        "    # Step 6: Predict the intent using the model\n",
        "    prediction = model.predict(input_vector)  # Ensure input is in the right format\n",
        "\n",
        "    # Step 7: Get the predicted intent\n",
        "    intent_index = np.argmax(prediction)  # Assuming softmax output\n",
        "    intents = list(responses.keys())\n",
        "    predicted_intent = intents[intent_index]\n",
        "\n",
        "    # Step 8: Fetch a random response for the predicted intent\n",
        "    response = random.choice(responses[predicted_intent])\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dOxoZg9LCugi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "dOxoZg9LCugi",
        "outputId": "0dba53ed-a420-4cc2-a6e0-23ebff68df6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Honored to assist! I'm clued in that you are unsure of how to check the status of your order with the order number {{Order Number}}. I'm here to help guide you through the process. To view the status of your order, you can visit the '{{Order Tracking}}' section on our website. This will provide you with real-time updates on the progress of your purchase. If you have any further questions or need additional assistance, please feel free to ask. It's my priority to ensure you have a seamless experience!\""
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_response(\"I need help with my order\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JL_B4lB4SKbu",
      "metadata": {
        "id": "JL_B4lB4SKbu"
      },
      "outputs": [],
      "source": [
        "def chat():\n",
        "    print(\"Chatbot: Hello! How can I assist you today?\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "        response = get_response(user_input)\n",
        "        print(\"Chatbot:\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wnRQIy1PScKn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnRQIy1PScKn",
        "outputId": "df1a108f-9540-4bc7-a3bf-9ed0e01b2c2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Hello! How can I assist you today?\n",
            "You: hello\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Chatbot: Glad you contacted to us for assistance in canceling your {{Account Category}} account. I understand that you no longer find value in your current subscription and we value your feedback. To cancel your {{Account Category}} account, please follow these steps:\n",
            "\n",
            "1. Log in to your account on our website.\n",
            "2. Navigate to the account settings page.\n",
            "3. Look for the option to manage your subscriptions.\n",
            "4. Locate the {{Account Category}} account subscription and select the cancellation option.\n",
            "5. Follow the prompts and confirm the cancellation of your {{Account Category}} account.\n",
            "\n",
            "If you encounter any difficulties or have any questions during the cancellation process, don't hesitate to reach out to our customer support team. We are here to assist you every step of the way. We appreciate your business and hope to serve you again in the future.\n",
            "You: i want to return my order\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Chatbot: Thank you for reaching out! I completely understand that you need assistance with checking the estimated time of arrival (ETA) for your order with order number {{Order Number}}. To provide you with the most accurate information, let me check the current status of your order. Please allow me a moment to gather the details.\n",
            "You: what i can do next\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Chatbot: Thank you for bringing your concern regarding the removal of your standard account to our attention. We understand that you would like to delete your account, and we're here to assist you with that process. To proceed with the deletion, please follow these steps:\n",
            "\n",
            "1. Log in to your account on our website.\n",
            "2. Go to your account settings or profile page.\n",
            "3. Locate the account deletion option or contact our customer support team directly for assistance.\n",
            "4. Follow the prompts or provide the necessary information to confirm the deletion.\n",
            "5. Once the deletion process is complete, you will receive a confirmation notification.\n",
            "\n",
            "Please keep in mind that deleting your standard account will permanently erase all your data and cannot be undone. If you have any further questions or encounter any difficulties during this process, feel free to reach out to us, and we'll be more than happy to help.\n",
            "You: exit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61dd5848",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T16:32:18.362830Z",
          "iopub.status.busy": "2024-10-16T16:32:18.361906Z",
          "iopub.status.idle": "2024-10-16T16:32:18.556263Z",
          "shell.execute_reply": "2024-10-16T16:32:18.555208Z",
          "shell.execute_reply.started": "2024-10-16T16:32:18.362786Z"
        },
        "id": "61dd5848",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# tokenizer = Tokenizer()\n",
        "# tokenizer.fit_on_texts(X_train)\n",
        "# X_train = tokenizer.texts_to_sequences(X_train)\n",
        "# X_test = tokenizer.texts_to_sequences(X_test)\n",
        "# X_val = tokenizer.texts_to_sequences(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad8520ec",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T16:32:20.303723Z",
          "iopub.status.busy": "2024-10-16T16:32:20.303288Z",
          "iopub.status.idle": "2024-10-16T16:32:20.332972Z",
          "shell.execute_reply": "2024-10-16T16:32:20.331894Z",
          "shell.execute_reply.started": "2024-10-16T16:32:20.303685Z"
        },
        "id": "ad8520ec",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# max_len = 100\n",
        "# X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "# X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "# X_val = pad_sequences(X_val, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e20405c0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-16T16:32:21.910508Z",
          "iopub.status.busy": "2024-10-16T16:32:21.910105Z",
          "iopub.status.idle": "2024-10-16T16:32:21.917322Z",
          "shell.execute_reply": "2024-10-16T16:32:21.916271Z",
          "shell.execute_reply.started": "2024-10-16T16:32:21.910471Z"
        },
        "id": "e20405c0",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# label_encoder = LabelEncoder()\n",
        "# y_train = label_encoder.fit_transform(y_train)\n",
        "# y_test = label_encoder.transform(y_test)\n",
        "# y_val = label_encoder.transform(y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z26ZyxojjhpA",
      "metadata": {
        "id": "z26ZyxojjhpA"
      },
      "source": [
        "## FULLY CONNCTED NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "768fc50c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T16:32:23.684757Z",
          "iopub.status.busy": "2024-10-16T16:32:23.683766Z",
          "iopub.status.idle": "2024-10-16T16:32:28.721299Z",
          "shell.execute_reply": "2024-10-16T16:32:28.720181Z",
          "shell.execute_reply.started": "2024-10-16T16:32:23.684710Z"
        },
        "id": "768fc50c",
        "outputId": "ee289422-fc20-45dc-c0cd-e582d7919c1d",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0770 - loss: 3.2506 - val_accuracy: 0.2922 - val_loss: 2.7265\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4024 - loss: 2.3461 - val_accuracy: 0.7090 - val_loss: 1.2772\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8162 - loss: 0.9460 - val_accuracy: 0.9169 - val_loss: 0.5283\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.3738 - val_accuracy: 0.9462 - val_loss: 0.2971\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9726 - loss: 0.1831 - val_accuracy: 0.9621 - val_loss: 0.2217\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.1071 - val_accuracy: 0.9719 - val_loss: 0.1738\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9905 - loss: 0.0710 - val_accuracy: 0.9756 - val_loss: 0.1499\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0535 - val_accuracy: 0.9768 - val_loss: 0.1325\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0387 - val_accuracy: 0.9780 - val_loss: 0.1212\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0273 - val_accuracy: 0.9804 - val_loss: 0.1181\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9882 - loss: 0.0913 \n",
            "Test loss: 0.11492770910263062\n",
            "Test accuracy: 0.9841075539588928\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=32, input_length=100))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "model.add(Dense(len(label_encoder.classes_), activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64)\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1UtMdl0rgV65",
      "metadata": {
        "id": "1UtMdl0rgV65"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4434268c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-10-15T20:23:42.982889Z",
          "iopub.status.busy": "2024-10-15T20:23:42.982442Z",
          "iopub.status.idle": "2024-10-15T20:23:43.268104Z",
          "shell.execute_reply": "2024-10-15T20:23:43.266872Z",
          "shell.execute_reply.started": "2024-10-15T20:23:42.982849Z"
        },
        "id": "4434268c",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "a58f1c38-ae55-41f2-caca-b40a0b8b3d03",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "['cancel_order' 'cancel_order' 'cancel_order' 'cancel_order'\n",
            " 'cancel_order' 'cancel_order' 'cancel_order' 'cancel_order'\n",
            " 'cancel_order' 'cancel_order' 'cancel_order' 'cancel_order'\n",
            " 'cancel_order' 'cancel_order' 'cancel_order' 'cancel_order'\n",
            " 'cancel_order' 'cancel_order' 'cancel_order' 'cancel_order'\n",
            " 'cancel_order' 'cancel_order' 'cancel_order' 'cancel_order'\n",
            " 'cancel_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_order' 'change_order' 'change_order' 'change_order'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'change_shipping_address'\n",
            " 'change_shipping_address' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee' 'place_order'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee' 'cancel_order'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_cancellation_fee'\n",
            " 'check_cancellation_fee' 'check_invoice' 'check_invoice' 'check_invoice'\n",
            " 'check_invoice' 'check_invoice' 'check_invoice' 'check_invoice'\n",
            " 'check_invoice' 'check_invoice' 'check_invoice' 'check_invoice'\n",
            " 'check_invoice' 'check_invoice' 'check_invoice' 'check_invoice'\n",
            " 'check_invoice' 'check_invoice' 'check_invoice' 'check_invoice'\n",
            " 'check_invoice' 'check_invoice' 'check_invoice' 'check_invoice'\n",
            " 'check_invoice' 'check_invoice' 'check_invoice' 'check_invoice'\n",
            " 'check_invoice' 'check_invoice' 'check_invoice' 'check_invoice'\n",
            " 'check_payment_methods' 'check_payment_methods' 'check_payment_methods'\n",
            " 'check_payment_methods' 'check_payment_methods' 'check_payment_methods'\n",
            " 'check_payment_methods' 'check_payment_methods' 'check_payment_methods'\n",
            " 'check_payment_methods' 'check_payment_methods' 'check_payment_methods'\n",
            " 'check_payment_methods' 'check_payment_methods' 'check_payment_methods'\n",
            " 'check_payment_methods' 'check_payment_methods' 'check_payment_methods'\n",
            " 'check_payment_methods' 'check_payment_methods' 'check_payment_methods'\n",
            " 'check_payment_methods' 'check_payment_methods' 'check_payment_methods'\n",
            " 'check_payment_methods' 'check_payment_methods' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'check_refund_policy' 'check_refund_policy' 'check_refund_policy'\n",
            " 'complaint' 'complaint' 'complaint' 'complaint' 'complaint' 'complaint'\n",
            " 'complaint' 'complaint' 'complaint' 'complaint' 'complaint' 'complaint'\n",
            " 'complaint' 'complaint' 'complaint' 'complaint' 'complaint' 'complaint'\n",
            " 'complaint' 'complaint' 'complaint' 'complaint' 'complaint'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_customer_service' 'contact_customer_service'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'contact_human_agent' 'contact_human_agent' 'contact_human_agent'\n",
            " 'create_account' 'switch_account' 'create_account' 'place_order'\n",
            " 'create_account' 'create_account' 'create_account' 'create_account'\n",
            " 'create_account' 'create_account' 'create_account' 'create_account'\n",
            " 'create_account' 'create_account' 'create_account' 'create_account'\n",
            " 'create_account' 'create_account' 'delete_account' 'create_account'\n",
            " 'create_account' 'create_account' 'create_account' 'create_account'\n",
            " 'create_account' 'delete_account' 'delete_account' 'delete_account'\n",
            " 'delete_account' 'delete_account' 'delete_account' 'delete_account'\n",
            " 'delete_account' 'delete_account' 'delete_account' 'delete_account'\n",
            " 'delete_account' 'delete_account' 'delete_account' 'delete_account'\n",
            " 'delete_account' 'delete_account' 'delete_account' 'delete_account'\n",
            " 'delete_account' 'delete_account' 'delete_account' 'delete_account'\n",
            " 'delete_account' 'delete_account' 'delete_account' 'delete_account'\n",
            " 'delete_account' 'delete_account' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_options' 'delivery_options' 'delivery_options'\n",
            " 'delivery_period' 'delivery_period' 'delivery_period' 'delivery_period'\n",
            " 'delivery_period' 'delivery_period' 'delivery_period' 'delivery_period'\n",
            " 'delivery_period' 'delivery_period' 'delivery_period' 'delivery_period'\n",
            " 'delivery_period' 'delivery_period' 'complaint' 'delivery_period'\n",
            " 'delivery_period' 'delivery_period' 'delivery_period' 'delivery_period'\n",
            " 'delivery_period' 'delivery_period' 'delivery_period' 'delivery_period'\n",
            " 'delivery_period' 'delivery_period' 'delivery_period' 'delivery_period'\n",
            " 'delivery_period' 'delivery_period' 'delivery_period' 'delivery_period'\n",
            " 'delivery_period' 'delivery_period' 'delivery_period' 'delivery_period'\n",
            " 'delivery_period' 'track_order' 'edit_account' 'edit_account'\n",
            " 'edit_account' 'edit_account' 'edit_account' 'edit_account'\n",
            " 'edit_account' 'edit_account' 'edit_account' 'edit_account'\n",
            " 'edit_account' 'edit_account' 'edit_account' 'edit_account'\n",
            " 'edit_account' 'edit_account' 'edit_account' 'edit_account'\n",
            " 'edit_account' 'edit_account' 'edit_account' 'edit_account'\n",
            " 'edit_account' 'edit_account' 'edit_account' 'edit_account'\n",
            " 'edit_account' 'edit_account' 'edit_account' 'edit_account'\n",
            " 'edit_account' 'edit_account' 'edit_account' 'edit_account'\n",
            " 'edit_account' 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice'\n",
            " 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice'\n",
            " 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice'\n",
            " 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice'\n",
            " 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice'\n",
            " 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice' 'get_invoice'\n",
            " 'get_invoice' 'get_invoice' 'get_refund' 'get_refund' 'get_refund'\n",
            " 'get_refund' 'get_refund' 'get_refund' 'get_refund' 'get_refund'\n",
            " 'get_refund' 'get_refund' 'get_refund' 'get_refund' 'get_refund'\n",
            " 'get_refund' 'get_refund' 'get_refund' 'get_refund' 'get_refund'\n",
            " 'get_refund' 'get_refund' 'get_refund' 'get_refund' 'get_refund'\n",
            " 'get_refund' 'get_refund' 'get_refund' 'get_refund' 'get_refund'\n",
            " 'newsletter_subscription' 'newsletter_subscription'\n",
            " 'newsletter_subscription' 'newsletter_subscription'\n",
            " 'newsletter_subscription' 'newsletter_subscription'\n",
            " 'newsletter_subscription' 'newsletter_subscription'\n",
            " 'newsletter_subscription' 'newsletter_subscription'\n",
            " 'newsletter_subscription' 'newsletter_subscription' 'edit_account'\n",
            " 'newsletter_subscription' 'newsletter_subscription'\n",
            " 'newsletter_subscription' 'newsletter_subscription'\n",
            " 'newsletter_subscription' 'newsletter_subscription'\n",
            " 'newsletter_subscription' 'newsletter_subscription'\n",
            " 'newsletter_subscription' 'newsletter_subscription' 'payment_issue'\n",
            " 'payment_issue' 'payment_issue' 'payment_issue' 'payment_issue'\n",
            " 'payment_issue' 'payment_issue' 'payment_issue' 'payment_issue'\n",
            " 'payment_issue' 'payment_issue' 'payment_issue' 'payment_issue'\n",
            " 'payment_issue' 'payment_issue' 'payment_issue' 'payment_issue'\n",
            " 'payment_issue' 'payment_issue' 'payment_issue' 'payment_issue'\n",
            " 'payment_issue' 'payment_issue' 'payment_issue' 'payment_issue'\n",
            " 'payment_issue' 'payment_issue' 'place_order' 'place_order' 'place_order'\n",
            " 'place_order' 'place_order' 'place_order' 'place_order' 'place_order'\n",
            " 'place_order' 'place_order' 'place_order' 'place_order' 'place_order'\n",
            " 'place_order' 'place_order' 'place_order' 'place_order' 'place_order'\n",
            " 'place_order' 'place_order' 'place_order' 'place_order' 'place_order'\n",
            " 'place_order' 'place_order' 'place_order' 'place_order' 'place_order'\n",
            " 'place_order' 'place_order' 'recover_password' 'recover_password'\n",
            " 'recover_password' 'recover_password' 'recover_password'\n",
            " 'recover_password' 'recover_password' 'recover_password'\n",
            " 'recover_password' 'recover_password' 'recover_password'\n",
            " 'recover_password' 'recover_password' 'recover_password'\n",
            " 'recover_password' 'recover_password' 'recover_password'\n",
            " 'recover_password' 'recover_password' 'recover_password'\n",
            " 'registration_problems' 'registration_problems' 'registration_problems'\n",
            " 'registration_problems' 'registration_problems' 'registration_problems'\n",
            " 'registration_problems' 'edit_account' 'registration_problems'\n",
            " 'registration_problems' 'registration_problems' 'registration_problems'\n",
            " 'create_account' 'registration_problems' 'registration_problems'\n",
            " 'registration_problems' 'registration_problems' 'registration_problems'\n",
            " 'registration_problems' 'registration_problems' 'registration_problems'\n",
            " 'registration_problems' 'registration_problems' 'registration_problems'\n",
            " 'registration_problems' 'registration_problems' 'registration_problems'\n",
            " 'review' 'review' 'review' 'review' 'review' 'review' 'review' 'review'\n",
            " 'review' 'review' 'review' 'review' 'review' 'review' 'review' 'review'\n",
            " 'review' 'review' 'review' 'review' 'review' 'review' 'review' 'review'\n",
            " 'review' 'review' 'review' 'review' 'review' 'review' 'review' 'review'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address'\n",
            " 'set_up_shipping_address' 'set_up_shipping_address' 'switch_account'\n",
            " 'switch_account' 'switch_account' 'switch_account' 'switch_account'\n",
            " 'switch_account' 'switch_account' 'switch_account' 'switch_account'\n",
            " 'switch_account' 'switch_account' 'switch_account' 'switch_account'\n",
            " 'switch_account' 'switch_account' 'switch_account' 'switch_account'\n",
            " 'switch_account' 'switch_account' 'delete_account' 'switch_account'\n",
            " 'switch_account' 'switch_account' 'switch_account' 'switch_account'\n",
            " 'switch_account' 'switch_account' 'switch_account' 'switch_account'\n",
            " 'switch_account' 'switch_account' 'switch_account' 'switch_account'\n",
            " 'switch_account' 'switch_account' 'switch_account' 'track_order'\n",
            " 'track_order' 'track_order' 'track_order' 'track_order' 'track_order'\n",
            " 'track_order' 'track_order' 'track_order' 'track_order' 'track_order'\n",
            " 'track_order' 'track_order' 'track_order' 'cancel_order' 'track_order'\n",
            " 'delivery_period' 'track_order' 'track_order' 'track_order' 'track_order'\n",
            " 'track_order' 'track_order' 'track_order' 'track_order' 'track_order'\n",
            " 'track_order' 'track_order' 'track_order' 'track_order' 'track_order'\n",
            " 'track_refund' 'track_refund' 'track_refund' 'track_refund'\n",
            " 'track_refund' 'track_refund' 'track_refund' 'track_refund'\n",
            " 'track_refund' 'track_refund' 'track_refund' 'track_refund'\n",
            " 'track_refund' 'track_refund' 'track_refund' 'track_refund'\n",
            " 'track_refund' 'track_refund' 'track_refund' 'track_refund'\n",
            " 'track_refund' 'track_refund' 'track_refund' 'track_refund'\n",
            " 'track_refund' 'track_refund' 'track_refund' 'track_refund']\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93af6b03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-15T20:24:08.676231Z",
          "iopub.status.busy": "2024-10-15T20:24:08.675719Z",
          "iopub.status.idle": "2024-10-15T20:24:08.690107Z",
          "shell.execute_reply": "2024-10-15T20:24:08.688303Z",
          "shell.execute_reply.started": "2024-10-15T20:24:08.676187Z"
        },
        "id": "93af6b03",
        "outputId": "5b227d8b-6f99-4c9a-e393-878fe804f5ed",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Actual Intent Predicted Intent\n",
            "0    cancel_order     cancel_order\n",
            "1    cancel_order     cancel_order\n",
            "2    cancel_order     cancel_order\n",
            "3    cancel_order     cancel_order\n",
            "4    cancel_order     cancel_order\n",
            "..            ...              ...\n",
            "813  track_refund     track_refund\n",
            "814  track_refund     track_refund\n",
            "815  track_refund     track_refund\n",
            "816  track_refund     track_refund\n",
            "817  track_refund     track_refund\n",
            "\n",
            "[818 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "results_df = pd.DataFrame({\"Actual Intent\": df_test['intent'], \"Predicted Intent\": y_pred})\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3ce1e88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-15T20:24:41.028271Z",
          "iopub.status.busy": "2024-10-15T20:24:41.027713Z",
          "iopub.status.idle": "2024-10-15T20:24:41.038985Z",
          "shell.execute_reply": "2024-10-15T20:24:41.037643Z",
          "shell.execute_reply.started": "2024-10-15T20:24:41.028224Z"
        },
        "id": "f3ce1e88",
        "outputId": "75033a6d-3d5e-46ec-e4f4-32157e9abdc4",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Actual Intent Predicted Intent\n",
            "116   check_cancellation_fee      place_order\n",
            "125   check_cancellation_fee     cancel_order\n",
            "315           create_account   switch_account\n",
            "317           create_account      place_order\n",
            "332           create_account   delete_account\n",
            "414          delivery_period        complaint\n",
            "437          delivery_period      track_order\n",
            "544  newsletter_subscription     edit_account\n",
            "639    registration_problems     edit_account\n",
            "644    registration_problems   create_account\n",
            "742           switch_account   delete_account\n",
            "773              track_order     cancel_order\n",
            "775              track_order  delivery_period\n"
          ]
        }
      ],
      "source": [
        "mismatch = results_df[results_df['Actual Intent'] != results_df['Predicted Intent']]\n",
        "\n",
        "print(mismatch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lrWzJozdj0lT",
      "metadata": {
        "id": "lrWzJozdj0lT"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f77433e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T16:32:36.548339Z",
          "iopub.status.busy": "2024-10-16T16:32:36.547310Z",
          "iopub.status.idle": "2024-10-16T16:33:30.123747Z",
          "shell.execute_reply": "2024-10-16T16:33:30.122647Z",
          "shell.execute_reply.started": "2024-10-16T16:32:36.548291Z"
        },
        "id": "2f77433e",
        "outputId": "f52cb56f-a2e1-48d1-e90b-4a0426354f87",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.1104 - loss: 3.1749 - val_accuracy: 0.2861 - val_loss: 2.3149\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4443 - loss: 1.8538 - val_accuracy: 0.8130 - val_loss: 0.9854\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8639 - loss: 0.7671 - val_accuracy: 0.9315 - val_loss: 0.4542\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9554 - loss: 0.3467 - val_accuracy: 0.9682 - val_loss: 0.2486\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9767 - loss: 0.1924 - val_accuracy: 0.9768 - val_loss: 0.1679\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.1090 - val_accuracy: 0.9804 - val_loss: 0.1232\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9905 - loss: 0.0742 - val_accuracy: 0.9829 - val_loss: 0.1021\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9954 - loss: 0.0459 - val_accuracy: 0.9817 - val_loss: 0.0806\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9972 - loss: 0.0332 - val_accuracy: 0.9829 - val_loss: 0.0774\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9968 - loss: 0.0264 - val_accuracy: 0.9878 - val_loss: 0.0680\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0974\n",
            "Test loss: 0.09243284910917282\n",
            "Test accuracy: 0.9841075539588928\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=max_sequence_length))\n",
        "\n",
        "model.add(LSTM(64))\n",
        "\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "\n",
        "model.add(Dense(len(label_encoder.classes_), activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64)\n",
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7177f3d4",
      "metadata": {
        "id": "7177f3d4",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ced59be9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-16T16:35:36.050783Z",
          "iopub.status.busy": "2024-10-16T16:35:36.050338Z",
          "iopub.status.idle": "2024-10-16T16:35:59.325521Z",
          "shell.execute_reply": "2024-10-16T16:35:59.324580Z",
          "shell.execute_reply.started": "2024-10-16T16:35:36.050741Z"
        },
        "id": "ced59be9",
        "outputId": "8d934588-082c-4414-ebd1-9db0a77d63b7",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - accuracy: 0.1058 - loss: 3.1491 - val_accuracy: 0.3460 - val_loss: 2.3905\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4278 - loss: 2.0303 - val_accuracy: 0.7262 - val_loss: 1.2157\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7938 - loss: 0.9594 - val_accuracy: 0.9205 - val_loss: 0.4653\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9489 - loss: 0.3187 - val_accuracy: 0.9633 - val_loss: 0.2040\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.1085 - val_accuracy: 0.9731 - val_loss: 0.1297\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0578 - val_accuracy: 0.9743 - val_loss: 0.1130\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0377 - val_accuracy: 0.9792 - val_loss: 0.1060\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0201 - val_accuracy: 0.9768 - val_loss: 0.0906\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0182 - val_accuracy: 0.9780 - val_loss: 0.0777\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0106 - val_accuracy: 0.9817 - val_loss: 0.0747\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.1058\n",
            "Test loss: 0.15559668838977814\n",
            "Test accuracy: 0.9853300452232361\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length= max_sequence_length))\n",
        "\n",
        "model.add(SimpleRNN(64))\n",
        "\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "\n",
        "model.add(Dense(len(label_encoder.classes_), activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64)\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f6d3f31",
      "metadata": {
        "id": "3f6d3f31",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the texts\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350d4491",
      "metadata": {
        "id": "350d4491",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3LXMujN0Ia4Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "3LXMujN0Ia4Q",
        "outputId": "39f76630-45e0-43ca-97b5-02f98f922499"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c84e60c3d64c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utterance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utterance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ],
      "source": [
        "train_texts = df_train['utterance'].values\n",
        "train_labels = df_train['intent'].values\n",
        "val_texts = df_val['utterance'].values\n",
        "val_labels = df_val['intent'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ZMO_eqcItD9",
      "metadata": {
        "id": "3ZMO_eqcItD9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from datasets import Dataset\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WaJs_xXkfo_L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "WaJs_xXkfo_L",
        "outputId": "13d82197-aae1-4318-ba71-d94b78372f97"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_labels' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-87f775e32ad7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
          ]
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "val_labels = label_encoder.transform(val_labels)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'input_ids': train_encodings['input_ids'],\n",
        "    'attention_mask': train_encodings['attention_mask'],\n",
        "    'labels': train_labels\n",
        "})\n",
        "\n",
        "val_dataset = Dataset.from_dict({\n",
        "    'input_ids': val_encodings['input_ids'],\n",
        "    'attention_mask': val_encodings['attention_mask'],\n",
        "    'labels': val_labels\n",
        "})\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cPy5X7yZgUH4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "cPy5X7yZgUH4",
        "outputId": "9108e99b-aa65-4720-9f35-eae4879029ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mas_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-1fc0dffea11e>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Fine-tune the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2237\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         batch = pad_without_fast_tokenizer_warning(\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpad_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpad_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Restore the state of the warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3558\u001b[0m                 \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3562\u001b[0m     def create_token_type_ids_from_sequences(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    776\u001b[0m                         \u001b[0;34m\"Please see if a fast version of this tokenizer is available to have this feature available.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                     ) from e\n\u001b[0;32m--> 778\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    779\u001b[0m                     \u001b[0;34m\"Unable to create tensor, you should probably activate truncation and/or padding with\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m                     \u001b[0;34m\" 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the texts and include labels\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# Add labels to the encodings\n",
        "train_encodings['labels'] = train_labels\n",
        "val_encodings['labels'] = y_val\n",
        "\n",
        "# Convert encodings to datasets\n",
        "train_dataset = Dataset.from_dict(train_encodings)\n",
        "val_dataset = Dataset.from_dict(val_encodings)\n",
        "\n",
        "# Initialize the data collator for padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load the pre-trained BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=27)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    report_to=\"none\"  # Disabling W&B logging (optional)\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8YSnUgNnlji_",
      "metadata": {
        "id": "8YSnUgNnlji_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 3191511,
          "sourceId": 5537432,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30786,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "mlflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.240723,
      "end_time": "2024-10-16T18:24:36.198170",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-10-16T18:24:08.957447",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
